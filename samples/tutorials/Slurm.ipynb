{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096d7434",
   "metadata": {},
   "source": [
    "# HPC Cluster - Slurm\n",
    "\n",
    "This tutorial demonstrates submiting and monitoring a job which is running an external SLURM system. We can submit jobs to a Slurm HPC cluster using the Bridge operator or submitting a Kubeflow Pipelines script which uses the Slurm pod, or using the Slurm pod directly. This tutorial will demonstrate the setup and deployment for running a test script, and how to use S3 for file upload and download for all three implementations. See also [README](https://github.ibm.com/Accelerated-Discovery/bridge-operator/tree/master/pods/slurm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f15ec3",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb33658",
   "metadata": {},
   "source": [
    "##  Setup \n",
    "\n",
    "#### S3\n",
    "Create the S3 bucket with input files\n",
    "\n",
    "- Create a test bucket on S3 called \"mybucket\" and upload the sample batch script `slurm_batch.sh`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580d00d",
   "metadata": {},
   "source": [
    "#### Create environment variables\n",
    "\n",
    "For these tests we need to specify our S3 and resource endpoints and S2 bucket name. If the job script, parameter file and metadata file are in S3 the we also need to provide the ```bucket:folder/filename```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env ENDPOINT=minio-kubeflow.apps.adp-rosa-2.5wcf.p1.openshiftapps.com\n",
    "%env BUCKET=mybucket\n",
    "%env RESOURCE_URL=http://ec2-3-139-236-142.us-east-2.compute.amazonaws.com:8082/slurm/v0.0.37/\n",
    "\n",
    "%env JOBSCRIPT=mybucket:slurm_batch.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d020338",
   "metadata": {},
   "source": [
    "#### Create the S3 and Slurm secrets needed by the pod\n",
    "\n",
    "Edit the S3 and Slurm secret yaml file with credentials to access S3. Then create these secrets in the namespace you wish to run jobs in, e.g. set env variable and  run in bridge-operator-system use \n",
    "\n",
    "NOTE for slurm you need to generate a token using e.g.\n",
    "`scontrol token lifespan=$((3600*24))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc467931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define env names for secrets to be used for all jobs\n",
    "%env S3_SECRET=mysecret-s3\n",
    "%env RESOURCE_SECRET=secret-slurm\n",
    "\n",
    "!sed -i '' \"s#{{S3_SECRET}}#$S3_SECRET#g\" ../core/secrets/s3secret.yaml \n",
    "!sed -i '' \"s#{{RESOURCE_SECRET}}#$RESOURCE_SECRET#g\" ../core/secrets/slurmsecret.yaml \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b88bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f ../core/secrets/slurmsecret.yaml -n bridge-operator-system\n",
    "!kubectl apply -f ../core/secrets/s3secret.yaml -n bridge-operator-system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913cf8b3",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce9037",
   "metadata": {},
   "source": [
    "## 1. Testing the Slurm pod directly\n",
    "\n",
    "Testing of individual pods can be done directly without invoking the Bridge operator.\n",
    "\n",
    "For Slurm the ```samples/tests/slurm/pod.yaml``` specifies\n",
    "- the pod image to use ```quay.io/ibmdpdev/slurm-pod:v0.0.1```\n",
    "- the jobname ```hpcjob```\n",
    "The secret name for both the resource and S3 must be set using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87004a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!sed -i '' \"s#{{S3_SECRET}}#$S3_SECRET#g\" ../test/slurm/pod.yaml\n",
    "!sed -i '' \"s#{{RESOURCE_SECRET}}#$RESOURCE_SECRET#g\" ../test/slurm/pod.yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb4871",
   "metadata": {},
   "source": [
    "The configmap yamls are in ```samples/tests/slurm/ ``` and there you must configure \n",
    "- the Minio endpoint\n",
    "- the S3 bucket name\n",
    "- the resource URL\n",
    "\n",
    "Run the following to set the envoirnment variables and create the configmap. Then submit the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd11176",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i '' \"s#{{ENDPOINT}}#$ENDPOINT#g\" ../test/slurm/hpcjob-sample0_cm.yaml\n",
    "!sed -i '' \"s#{{RESOURCE_URL}}#$RESOURCE_URL#g\" ../test/slurm/hpcjob-sample0_cm.yaml\n",
    "!sed -i '' \"s#{{RESOURCE_SECRET}}#$RESOURCE_SECRET#g\" ../test/slurm/hpcjob-sample0_cm.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d76ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f ../test/slurm/hpcjob-sample0_cm.yaml\n",
    "!kubectl apply -f ../test/slurm/pod.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monitor the job\n",
    "!kubectl logs hpcjob-pod\n",
    "!kubectl describe pod hpcjob-pod\n",
    "# Once the job completes the log file will be in the S3 bucket specified in the configmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806bbb2d",
   "metadata": {},
   "source": [
    "## 2. Bridge operator for Slurm\n",
    "\n",
    "There are two sample yaml files in ```samples/core/operator``` for running jobs to a Slurm cluster using the Bridge operator.\n",
    "Before running either job edit the files so that \n",
    "\n",
    "- S3storage: endpoint: corresponds to your S3 endpoint\n",
    "- S3upload: bucket: corresponds to your bucket in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b25514",
   "metadata": {},
   "source": [
    "### Remote script and inline job parameters example \n",
    "The ```job0slurm.yaml``` submits a simple job script which is 'inline'.\n",
    "To edit the yaml and run the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "!sed -i '' \"s#{{RESOURCE_URL}}#$RESOURCE_URL#g\" ../core/operator/job0slurm.yaml\n",
    "!sed -i '' \"s#{{RESOURCE_SECRET}}#$RESOURCE_SECRET#g\" ../core/operator/job0slurm.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ebd58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f ../core/operator/job0slurm.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da09704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18c992ec",
   "metadata": {},
   "source": [
    "### Inline script and job parameters example\n",
    "The ```job1qslurm.yaml``` submits a job script which is in S3. \n",
    "To run the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186de7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i '' \"s#{{RESOURCE_URL}}#$RESOURCE_URL#g\" ../core/operator/job1slurm.yaml\n",
    "!sed -i '' \"s#{{ENDPOINT}}#$ENDPOINT#g\" ../core/operator/job1slurm.yaml\n",
    "!sed -i '' \"s#{{JOBSCRIPT}}#$JOBSCRIPT#g\" ../core/operator/job1slurm.yaml\n",
    "\n",
    "!sed -i '' \"s#{{S3_SECRET}}#$S3_SECRET#g\" ../core/operator/job1slurm.yaml\n",
    "!sed -i '' \"s#{{RESOURCE_SECRET}}#$RESOURCE_SECRET#g\" ../core/operator/job1slurm.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d66bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f ../core/operator/job1slurm.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed47aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf5a1287",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab9483",
   "metadata": {},
   "source": [
    "## 3. KubeFlow Pipelines\n",
    "\n",
    "These examples assume you have access to a KFP with Tekton installation where you can submit and run jobs or upload pipelines to the KFP UI. See e.g. ``` bridge-operator/kubeflow/```\n",
    "\n",
    "The credentials for S3 and the external resource should be saved to the kubeflow namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f ../core/secrets/slurmsecret.yaml -n kubeflow\n",
    "!kubectl apply -f ../core/secrets/s3secret.yaml -n kubeflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb120ce",
   "metadata": {},
   "source": [
    "The implementation with KubeFlow Pipelines uses a general ```bridge-pipeline``` given in ```kubeflow/bridge_pipeline_handler.py``` and the specific implementation for Slurm is in ```kubeflow/implementations/slurm_invoker.py```\n",
    "\n",
    "1. compile the bridge pipeline\n",
    "\n",
    "``` $ python bridge_pipeline_handler.py ```\n",
    "\n",
    "2. Upload the generated yaml to the KFP UI > pipelines\n",
    "\n",
    "\n",
    "3. Run ```kubeflow/implementations/slurm_invoker.py``` providing\n",
    "\n",
    "- a host endpoint for KFP\n",
    "- a ```s3endpoint``` for S3 \n",
    "- a ```s3_secret``` name \n",
    "- a ```resource_secret``` name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a8262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the job\n",
    "!python ../../kubeflow/implementations/slurm_invoker.py --kfphost=<KFP_HOST> \\\n",
    "                                                      --s3endpoint=<s3ENDPOINT> --s3_secret=<S3_SECRET> \\\n",
    "                                                      --script=<BUCKET:SCRIPT> --resource_secret=<RESOURCE_SECRET>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9f011",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0cdec5d",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f841f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
